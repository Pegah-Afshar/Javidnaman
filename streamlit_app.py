import streamlit as st
from streamlit_gsheets import GSheetsConnection
import pandas as pd

# Û±. ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµÙØ­Ù‡
st.set_config(page_title="Ø«Ø¨Øª Ùˆ ÙˆÛŒØ±Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª", layout="wide")

# Û². Ø§Ø³ØªØ§ÛŒÙ„â€ŒØ¯Ù‡ÛŒ Ø±Ø§Ø³Øªâ€ŒÚ†ÛŒÙ† Ùˆ ÙÛŒÚ©Ø³ Ú©Ø±Ø¯Ù† Ù…Ø´Ú©Ù„ Ø¨Ø§Ú©Ø³ Ù†Ø§Ù…
st.markdown("""
    <style>
    [data-testid="stAppViewContainer"] { direction: rtl; text-align: right; }
    label, .stTextInput, .stTextArea, .stSelectbox { direction: rtl !important; text-align: right !important; }
    .stButton button { display: block; margin-right: 0; margin-left: auto; background-color: #4CAF50; color: white; }
    input { direction: rtl; text-align: right; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ“‹ Ù¾Ù†Ù„ Ø¬Ø§Ù…Ø¹ Ø«Ø¨Øª Ùˆ ÙˆÛŒØ±Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª")

# Û³. Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ú¯ÙˆÚ¯Ù„â€ŒØ´ÛŒØª
try:
    spreadsheet_url = st.secrets["public_gsheets_url"]
    conn = st.connection("gsheets", type=GSheetsConnection)
    df = conn.read(spreadsheet=spreadsheet_url, ttl=0)
except Exception as e:
    st.error("Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ú¯ÙˆÚ¯Ù„â€ŒØ´ÛŒØª.")
    st.stop()

# Û´. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù„ÛŒØ³Øª Ø§Ø³Ø§Ù…ÛŒ
names_list = df['Ø§Ø³Ù…'].dropna().unique().tolist()

# Ù…Ù†ÙˆÛŒ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ±Ø§ÛŒØ´
search_query = st.selectbox(
    "ğŸ” Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ±Ø§ÛŒØ´ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ (Ø¨Ø±Ø§ÛŒ Ø«Ø¨Øª Ø¬Ø¯ÛŒØ¯ Ø±ÙˆÛŒ Ú¯Ø²ÛŒÙ†Ù‡ Ø§ÙˆÙ„ Ø¨Ù…Ø§Ù†ÛŒØ¯):", 
    ["+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯"] + names_list
)

# Ûµ. ÙØ±Ù… Ø§ØµÙ„ÛŒ
with st.form("main_form"):
    if search_query == "+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯":
        st.subheader("âœ¨ Ø«Ø¨Øª ÙˆØ±ÙˆØ¯ÛŒ Ø¬Ø¯ÛŒØ¯")
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù„ÛŒØ³Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¯Ø± Ù¾Ø´Øª ØµØ­Ù†Ù‡ (Datalist)
        # Ø§ÛŒÙ† Ú©Ø¯ Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ ÙˆÙ‚ØªÛŒ Ø¯Ø± Ø¨Ø§Ú©Ø³ Ù…ØªÙ† ØªØ§ÛŒÙ¾ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ØŒ Ù„ÛŒØ³Øª Ø§Ø³Ø§Ù…ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø²ÛŒØ± Ø¢Ù† Ø¸Ø§Ù‡Ø± Ø´ÙˆØ¯
        options_html = "".join([f'<option value="{n}">' for n in names_list])
        st.markdown(f'<datalist id="names_list">{options_html}</datalist>', unsafe_allow_html=True)
        
        # ØªÙ†Ù‡Ø§ Ø¨Ø§Ú©Ø³ Ù†Ø§Ù…: Ø§ÛŒÙ† ÛŒÚ© text_input Ø§Ø³Øª Ù¾Ø³ Ø¨Ø§ Ú©Ù„ÛŒÚ© Ø±ÙˆÛŒ Ø¨Ø§Ú©Ø³ Ø¨Ø¹Ø¯ÛŒ Ù¾Ø§Ú© Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯
        v_name = st.text_input("Ø§Ø³Ù…:", key="unique_name_input", placeholder="ØªØ§ÛŒÙ¾ Ú©Ù†ÛŒØ¯ (Ù„ÛŒØ³Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¸Ø§Ù‡Ø± Ù…ÛŒâ€ŒØ´ÙˆØ¯)...")
        
        # ØªØ²Ø±ÛŒÙ‚ Ø¬Ø§ÙˆØ§Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ø±Ø§ÛŒ Ù…ØªØµÙ„ Ú©Ø±Ø¯Ù† Ù„ÛŒØ³Øª Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡ Ø¨Ø§Ú©Ø³ Ù…ØªÙ†
        st.markdown("""
            <script>
            var inputs = window.parent.document.querySelectorAll('input[type="text"]');
            for (var i = 0; i < inputs.length; i++) {
                if (inputs[i].getAttribute('aria-label') == "Ø§Ø³Ù…:") {
                    inputs[i].setAttribute('list', 'names_list');
                }
            }
            </script>
            """, unsafe_allow_html=True)
    else:
        st.subheader(f"ğŸ”„ ÙˆÛŒØ±Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª: {search_query}")
        user_data = df[df['Ø§Ø³Ù…'] == search_query].iloc[0]
        v_name = search_query

    # --- Ø¨Ø®Ø´ Û±: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø®ØµÛŒ ---
    st.markdown("### ğŸ‘¤ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø´Ø®ØµÛŒ")
    col1, col2, col3 = st.columns(3)
    with col1: v_bday = st.text_input("ØªØ§Ø±ÛŒØ® ØªÙˆÙ„Ø¯", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("ØªØ§Ø±ÛŒØ® ØªÙˆÙ„Ø¯", "")))
    with col2: v_age = st.text_input("Ø³Ù†", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ø³Ù†", "")))
    with col3: v_gender = st.text_input("Ø¬Ù†Ø³ÛŒØª", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ø¬Ù†Ø³ÛŒØª", "")))
    
    v_birth_place = st.text_input("Ù…Ø­Ù„ ØªÙˆÙ„Ø¯", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ù…Ø­Ù„ ØªÙˆÙ„Ø¯", "")))

    st.divider()

    # --- Ø¨Ø®Ø´ Û²: Ø¬Ø²Ø¦ÛŒØ§Øª ÙˆØ§Ù‚Ø¹Ù‡ ---
    st.markdown("### ğŸ” Ø¬Ø²Ø¦ÛŒØ§Øª ÙˆØ§Ù‚Ø¹Ù‡")
    
    det_col1, det_col2, det_col3 = st.columns(3)
    with det_col1: 
        v_province = st.text_input("Ø§Ø³ØªØ§Ù†", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ø§Ø³ØªØ§Ù†", "")))
    with det_col2: 
        v_city = st.text_input("Ø´Ù‡Ø±", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ø´Ù‡Ø±", "")))
    with det_col3: 
        v_district_street = st.text_input("Ù…Ø­Ù„Ù‡/Ø®ÛŒØ§Ø¨Ø§Ù†", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ù…Ø­Ù„Ù‡/Ø®ÛŒØ§Ø¨Ø§Ù†", "")))
    
    date_col1, date_col2 = st.columns(2)
    with date_col1:
        v_date_shamsi = st.text_input("ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ", "")))
    with date_col2:
        v_date_en = st.text_input("ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ", "")))
    
    v_exact_loc = st.text_input("Ù…Ø­Ù„ Ø¯Ù‚ÛŒÙ‚ Ú©Ø´ØªÙ‡ Ø´Ø¯Ù†", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ù…Ø­Ù„ Ø¯Ù‚ÛŒÙ‚ Ú©Ø´ØªÙ‡ Ø´Ø¯Ù†", "")))
    v_method = st.text_input("Ø·Ø±ÛŒÙ‚Ù‡â€ŒÛŒ Ú©Ø´ØªÙ‡ Ø´Ø¯Ù†", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ø·Ø±ÛŒÙ‚Ù‡â€ŒÛŒ Ú©Ø´ØªÙ‡ Ø´Ø¯Ù†", "")))
    v_grave = st.text_input("Ø¢Ø±Ø§Ù…Ú¯Ø§Ù‡", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ø¢Ø±Ø§Ù…Ú¯Ø§Ù‡", "")))

    st.divider()

    # --- Ø¨Ø®Ø´ Û³: Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÚ©Ù…ÛŒÙ„ÛŒ ---
    v_social = st.text_input("Ø§Ú©Ø§Ù†Øª Ø¯Ø± Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ø§Ú©Ø§Ù†Øª Ø¯Ø± Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ", "")))
    v_relatives = st.text_input("Ø¨Ø³ØªÚ¯Ø§Ù† Ø¯Ø± Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("Ø¨Ø³ØªÚ¯Ø§Ù† Ø¯Ø± Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ", "")))
    v_notes = st.text_area("ØªÙˆØ¶ÛŒØ­Ø§Øª", value="" if search_query=="+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯" else str(user_data.get("ØªÙˆØ¶ÛŒØ­Ø§Øª", "")))

    submit = st.form_submit_button("ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ")

    if submit:
        if not v_name or v_name.strip() == "":
            st.error("âš ï¸ Ù†Ø§Ù… Ø§Ù„Ø²Ø§Ù…ÛŒ Ø§Ø³Øª.")
        else:
            updated_dict = {
                "Ø§Ø³Ù…": v_name, "Ø§Ø³ØªØ§Ù†": v_province, "Ø´Ù‡Ø±": v_city, "Ù…Ø­Ù„Ù‡/Ø®ÛŒØ§Ø¨Ø§Ù†": v_district_street, 
                "ØªØ§Ø±ÛŒØ® Ø´Ù…Ø³ÛŒ": v_date_shamsi, "ØªØ§Ø±ÛŒØ® Ù…ÛŒÙ„Ø§Ø¯ÛŒ": v_date_en, "Ù…Ø­Ù„ Ø¯Ù‚ÛŒÙ‚ Ú©Ø´ØªÙ‡ Ø´Ø¯Ù†": v_exact_loc,
                "Ø·Ø±ÛŒÙ‚Ù‡â€ŒÛŒ Ú©Ø´ØªÙ‡ Ø´Ø¯Ù†": v_method, "Ø¢Ø±Ø§Ù…Ú¯Ø§Ù‡": v_grave, "Ø³Ù†": v_age, "Ø¬Ù†Ø³ÛŒØª": v_gender, 
                "ØªÙˆØ¶ÛŒØ­Ø§Øª": v_notes, "Ù…Ø­Ù„ ØªÙˆÙ„Ø¯": v_birth_place, "ØªØ§Ø±ÛŒØ® ØªÙˆÙ„Ø¯": v_bday, 
                "Ø§Ú©Ø§Ù†Øª Ø¯Ø± Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ": v_social, "Ø¨Ø³ØªÚ¯Ø§Ù† Ø¯Ø± Ø´Ø¨Ú©Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ": v_relatives
            }
            
            try:
                if search_query == "+ Ø§ÙØ²ÙˆØ¯Ù† Ù…ÙˆØ±Ø¯ Ø¬Ø¯ÛŒØ¯":
                    new_row = pd.DataFrame([updated_dict])
                    df = pd.concat([df, new_row], ignore_index=True)
                    conn.update(spreadsheet=spreadsheet_url, data=df)
                    st.success(f"'{v_name}' Ø«Ø¨Øª Ø´Ø¯.")
                else:
                    df.loc[df['Ø§Ø³Ù…'] == search_query, list(updated_dict.keys())] = list(updated_dict.values())
                    conn.update(spreadsheet=spreadsheet_url, data=df)
                    st.success("Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯.")
                st.rerun()
            except Exception as e:
                st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡: {e}")
